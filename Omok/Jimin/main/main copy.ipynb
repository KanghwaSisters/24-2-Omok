{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting & Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 현재 파일(main.ipynb)이 있는 디렉토리의 부모 디렉토리를 sys.path에 추가\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO \n",
    "from gameInfo import *\n",
    "from fileInfo import *\n",
    "from Omok.Jimin.main.config import *\n",
    "from Omok.Jimin.utils.setDevice import *\n",
    "from timer import *\n",
    "\n",
    "# CODES\n",
    "from state.ver2 import *\n",
    "from network.resnet import *\n",
    "from trainer.ver1 import *\n",
    "from eval.ver1 import *\n",
    "from selfplay.ver1 import *\n",
    "from tester.ver2 import *\n",
    "from utils.saveLoad import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "State = select_state(STATE_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "previous_time = start\n",
    "\n",
    "# 시각화용 \n",
    "win_rates = []\n",
    "\n",
    "# model 정의\n",
    "model = Network(N_RESIDUAL_BLOCK, N_KERNEL, STATE_DIM, N_ACTIONS)\n",
    "model = model.to(device)\n",
    "\n",
    "self_play = SelfPlay(model, TRAIN_TEMPERATURE, TEMP_DISCOUNT, N_SELFPLAY, N_PLAYOUT)\n",
    "train = TrainNetwork(model, BATCH_SIZE, LEARNING_RATE, LEARN_DECAY, LEARN_EPOCH)\n",
    "eval_network = EvalNetwork(model, EVAL_GAME_COUNT, EVAL_TEMPERATURE, N_PLAYOUT)\n",
    "\n",
    "# 경로 생성\n",
    "make_directory(F_PATH)\n",
    "\n",
    "# 학습\n",
    "for i in range(N_ITER):\n",
    "    print(f'\\n - [ {i+1} ] --------------------------------')\n",
    "\n",
    "    # 나눠서 selfplay \n",
    "    self_play(i)\n",
    "\n",
    "    h, m, s = convert_seconds(time.time() - previous_time)\n",
    "    previous_time = time.time() \n",
    "    print(f\">>> selfplay에 소요된 시간은 {h}시간 {m}분 {s}초 입니다. \\n\")\n",
    "    \n",
    "    # 학습 \n",
    "    train(self_play.history)\n",
    "\n",
    "    h, m, s = convert_seconds(time.time() - previous_time)\n",
    "    previous_time = time.time() \n",
    "    print(f\">>> 학습에 소요된 시간은 {h}시간 {m}분 {s}초 입니다. \\n\")\n",
    "\n",
    "    save_model(train.model, f_name='latest_model_weight')\n",
    "\n",
    "    if (i+1) % 5 == 0:    \n",
    "        eval_network(train.model)\n",
    "        win_rates.append(eval_network.win_rate)\n",
    "\n",
    "        h, m, s = convert_seconds(time.time() - previous_time)\n",
    "        previous_time = time.time() \n",
    "        print(f\">>> Eval에 소요된 시간은 {h}시간 {m}분 {s}초 입니다. \\n\")\n",
    "\n",
    "    if (i+1) % 10 == 0:\n",
    "        eval_network.visualize_game(download=True, idx=i+1)\n",
    "        print(f\"current temp is {self_play.temp}\")\n",
    "\n",
    "    if eval_network.updated:\n",
    "        self_play.update_model(train.model)\n",
    "        eval_network.updated = False\n",
    "\n",
    "h, m, s = convert_seconds(time.time() - start)\n",
    "print(f\"총 학습에 걸린 시간은 {h}시간 {m}분 {s}초 입니다. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download hyper params \n",
    "save_as_txt('hyperParams', hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TrainNetwork(model, BATCH_SIZE, 0.001, LEARN_DECAY, LEARN_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_win_rate(win_rates, path=F_PATH, download=True)\n",
    "visualize_loss(train.losses, path=F_PATH, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - [ 101 ] --------------------------------\n",
      "self play :  2 / 20 | 2002 / 2000\n",
      "self play :  4 / 20 | 2004 / 2000\n",
      "self play :  6 / 20 | 2006 / 2000\n",
      "self play :  8 / 20 | 2008 / 2000\n",
      "self play :  10 / 20 | 2010 / 2000\n",
      "self play :  12 / 20 | 2012 / 2000\n",
      "self play :  14 / 20 | 2014 / 2000\n",
      "self play :  16 / 20 | 2016 / 2000\n",
      "self play :  18 / 20 | 2018 / 2000\n",
      "self play :  20 / 20 | 2020 / 2000\n",
      ">>> selfplay에 소요된 시간은 0시간 8분 37초 입니다. \n",
      "\n",
      "\n",
      "> Train Started.\n",
      "step : 100 / 1000 | (mean) p_loss : 1.262 v_loss : 0.721 | lr : [0.001]\n",
      "step : 200 / 1000 | (mean) p_loss : 1.230 v_loss : 0.704 | lr : [0.001]\n",
      "step : 300 / 1000 | (mean) p_loss : 1.212 v_loss : 0.698 | lr : [0.001]\n",
      "step : 400 / 1000 | (mean) p_loss : 1.201 v_loss : 0.694 | lr : [0.001]\n",
      "step : 500 / 1000 | (mean) p_loss : 1.193 v_loss : 0.692 | lr : [0.001]\n",
      "step : 600 / 1000 | (mean) p_loss : 1.187 v_loss : 0.690 | lr : [0.001]\n",
      "step : 700 / 1000 | (mean) p_loss : 1.181 v_loss : 0.688 | lr : [0.001]\n",
      "step : 800 / 1000 | (mean) p_loss : 1.179 v_loss : 0.687 | lr : [0.001]\n",
      "step : 900 / 1000 | (mean) p_loss : 1.176 v_loss : 0.686 | lr : [0.001]\n",
      "step : 1000 / 1000 | (mean) p_loss : 1.173 v_loss : 0.685 | lr : [0.001]\n",
      "> Train Ended.\n",
      ">>> 학습에 소요된 시간은 0시간 0분 32초 입니다. \n",
      "\n",
      "latest_model_weight saved successfully!\n",
      "\n",
      " - [ 102 ] --------------------------------\n",
      "self play :  2 / 20 | 2022 / 2000\n",
      "self play :  4 / 20 | 2024 / 2000\n",
      "self play :  6 / 20 | 2026 / 2000\n",
      "self play :  8 / 20 | 2028 / 2000\n",
      "self play :  10 / 20 | 2030 / 2000\n",
      "self play :  12 / 20 | 2032 / 2000\n",
      "self play :  14 / 20 | 2034 / 2000\n",
      "self play :  16 / 20 | 2036 / 2000\n",
      "self play :  18 / 20 | 2038 / 2000\n",
      "self play :  20 / 20 | 2040 / 2000\n",
      ">>> selfplay에 소요된 시간은 0시간 8분 33초 입니다. \n",
      "\n",
      "\n",
      "> Train Started.\n",
      "step : 100 / 1000 | (mean) p_loss : 1.169 v_loss : 0.687 | lr : [0.001]\n",
      "step : 200 / 1000 | (mean) p_loss : 1.168 v_loss : 0.689 | lr : [0.001]\n",
      "step : 300 / 1000 | (mean) p_loss : 1.166 v_loss : 0.690 | lr : [0.001]\n",
      "step : 400 / 1000 | (mean) p_loss : 1.163 v_loss : 0.691 | lr : [0.001]\n",
      "step : 500 / 1000 | (mean) p_loss : 1.160 v_loss : 0.691 | lr : [0.001]\n",
      "step : 600 / 1000 | (mean) p_loss : 1.157 v_loss : 0.691 | lr : [0.001]\n",
      "step : 700 / 1000 | (mean) p_loss : 1.154 v_loss : 0.691 | lr : [0.001]\n",
      "step : 800 / 1000 | (mean) p_loss : 1.152 v_loss : 0.691 | lr : [0.001]\n",
      "step : 900 / 1000 | (mean) p_loss : 1.150 v_loss : 0.690 | lr : [0.001]\n",
      "step : 1000 / 1000 | (mean) p_loss : 1.148 v_loss : 0.690 | lr : [0.001]\n",
      "> Train Ended.\n",
      ">>> 학습에 소요된 시간은 0시간 0분 32초 입니다. \n",
      "\n",
      "latest_model_weight saved successfully!\n",
      "\n",
      " - [ 103 ] --------------------------------\n",
      "self play :  2 / 20 | 2042 / 2000\n",
      "self play :  4 / 20 | 2044 / 2000\n",
      "self play :  6 / 20 | 2046 / 2000\n",
      "self play :  8 / 20 | 2048 / 2000\n",
      "self play :  10 / 20 | 2050 / 2000\n",
      "self play :  12 / 20 | 2052 / 2000\n",
      "self play :  14 / 20 | 2054 / 2000\n",
      "self play :  16 / 20 | 2056 / 2000\n",
      "self play :  18 / 20 | 2058 / 2000\n",
      "self play :  20 / 20 | 2060 / 2000\n",
      ">>> selfplay에 소요된 시간은 0시간 8분 34초 입니다. \n",
      "\n",
      "\n",
      "> Train Started.\n",
      "step : 100 / 1000 | (mean) p_loss : 1.145 v_loss : 0.692 | lr : [0.001]\n",
      "step : 200 / 1000 | (mean) p_loss : 1.144 v_loss : 0.692 | lr : [0.001]\n",
      "step : 300 / 1000 | (mean) p_loss : 1.142 v_loss : 0.694 | lr : [0.001]\n",
      "step : 400 / 1000 | (mean) p_loss : 1.139 v_loss : 0.694 | lr : [0.001]\n",
      "step : 500 / 1000 | (mean) p_loss : 1.136 v_loss : 0.695 | lr : [0.001]\n",
      "step : 600 / 1000 | (mean) p_loss : 1.134 v_loss : 0.696 | lr : [0.001]\n",
      "step : 700 / 1000 | (mean) p_loss : 1.132 v_loss : 0.696 | lr : [0.001]\n",
      "step : 800 / 1000 | (mean) p_loss : 1.130 v_loss : 0.696 | lr : [0.001]\n",
      "step : 900 / 1000 | (mean) p_loss : 1.128 v_loss : 0.697 | lr : [0.001]\n",
      "step : 1000 / 1000 | (mean) p_loss : 1.127 v_loss : 0.697 | lr : [0.001]\n",
      "> Train Ended.\n",
      ">>> 학습에 소요된 시간은 0시간 0분 32초 입니다. \n",
      "\n",
      "latest_model_weight saved successfully!\n",
      "\n",
      " - [ 104 ] --------------------------------\n",
      "self play :  2 / 20 | 2062 / 2000\n",
      "self play :  4 / 20 | 2064 / 2000\n",
      "self play :  6 / 20 | 2066 / 2000\n",
      "self play :  8 / 20 | 2068 / 2000\n",
      "self play :  10 / 20 | 2070 / 2000\n",
      "self play :  12 / 20 | 2072 / 2000\n",
      "self play :  14 / 20 | 2074 / 2000\n",
      "self play :  16 / 20 | 2076 / 2000\n",
      "self play :  18 / 20 | 2078 / 2000\n",
      "self play :  20 / 20 | 2080 / 2000\n",
      ">>> selfplay에 소요된 시간은 0시간 8분 55초 입니다. \n",
      "\n",
      "\n",
      "> Train Started.\n",
      "step : 100 / 1000 | (mean) p_loss : 1.126 v_loss : 0.698 | lr : [0.001]\n",
      "step : 200 / 1000 | (mean) p_loss : 1.125 v_loss : 0.699 | lr : [0.001]\n",
      "step : 300 / 1000 | (mean) p_loss : 1.124 v_loss : 0.700 | lr : [0.001]\n",
      "step : 400 / 1000 | (mean) p_loss : 1.122 v_loss : 0.700 | lr : [0.001]\n",
      "step : 500 / 1000 | (mean) p_loss : 1.120 v_loss : 0.701 | lr : [0.001]\n",
      "step : 600 / 1000 | (mean) p_loss : 1.118 v_loss : 0.701 | lr : [0.001]\n",
      "step : 700 / 1000 | (mean) p_loss : 1.116 v_loss : 0.702 | lr : [0.001]\n",
      "step : 800 / 1000 | (mean) p_loss : 1.114 v_loss : 0.702 | lr : [0.001]\n",
      "step : 900 / 1000 | (mean) p_loss : 1.113 v_loss : 0.702 | lr : [0.001]\n",
      "step : 1000 / 1000 | (mean) p_loss : 1.111 v_loss : 0.703 | lr : [0.001]\n",
      "> Train Ended.\n",
      ">>> 학습에 소요된 시간은 0시간 0분 32초 입니다. \n",
      "\n",
      "latest_model_weight saved successfully!\n",
      "\n",
      " - [ 105 ] --------------------------------\n",
      "self play :  2 / 20 | 2082 / 2000\n",
      "self play :  4 / 20 | 2084 / 2000\n",
      "self play :  6 / 20 | 2086 / 2000\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "previous_time = start\n",
    "\n",
    "# 학습\n",
    "for i in range(100,150):\n",
    "    print(f'\\n - [ {i+1} ] --------------------------------')\n",
    "\n",
    "    # 나눠서 selfplay \n",
    "    self_play(i)\n",
    "\n",
    "    h, m, s = convert_seconds(time.time() - previous_time)\n",
    "    previous_time = time.time() \n",
    "    print(f\">>> selfplay에 소요된 시간은 {h}시간 {m}분 {s}초 입니다. \\n\")\n",
    "    \n",
    "    # 학습 \n",
    "    train(self_play.history)\n",
    "\n",
    "    h, m, s = convert_seconds(time.time() - previous_time)\n",
    "    previous_time = time.time() \n",
    "    print(f\">>> 학습에 소요된 시간은 {h}시간 {m}분 {s}초 입니다. \\n\")\n",
    "\n",
    "    save_model(train.model, f_name='latest_model_weight')\n",
    "\n",
    "    if (i+1) % 5 == 0:    \n",
    "        eval_network(train.model)\n",
    "        win_rates.append(eval_network.win_rate)\n",
    "\n",
    "        h, m, s = convert_seconds(time.time() - previous_time)\n",
    "        previous_time = time.time() \n",
    "        print(f\">>> Eval에 소요된 시간은 {h}시간 {m}분 {s}초 입니다. \\n\")\n",
    "\n",
    "    if (i+1) % 10 == 0:\n",
    "        eval_network.visualize_game(download=True, idx=i+1)\n",
    "        print(f\"current temp is {self_play.temp}\")\n",
    "\n",
    "    if eval_network.updated:\n",
    "        self_play.update_model(train.model)\n",
    "        eval_network.updated = False\n",
    "\n",
    "h, m, s = convert_seconds(time.time() - start)\n",
    "print(f\"총 학습에 걸린 시간은 {h}시간 {m}분 {s}초 입니다. \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiGO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
